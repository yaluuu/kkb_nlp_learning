{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Can you come up out 3 sceneraies which use AI methods?  \n",
    "Ans: \n",
    "> 1. 智能管家（智能音箱）\n",
    "> 2. 机器翻译 \n",
    "> 3. 舆情分析\n",
    "\n",
    "1. How do we use Github; Why do we use Jupyter and Pycharm;  \n",
    "Ans: \n",
    "> github是一个免费的代码管理平台，可以方便的分享、交流、学习，支持多种语言的语法着色，阅读方便；  \n",
    "> jupyter是一个交互式的笔记工具，支持代码运行，可以直接显示代码运行结果和画图，用于展示交流十分方便；  \n",
    "> jupyter运行时存储了每一步的所有变量，一般不用于大型项目，Pycharm可用于构建大型项目。\n",
    "\n",
    "2. What's the Probability Model?  \n",
    "Ans:\n",
    "> 用数学概率的方法来表示不同随机变量之间不确定关系的数学模型。\n",
    "\n",
    "3. Can you came up with some sceneraies at which we could use Probability Model?  \n",
    "Ans:\n",
    "> 1. 信用欺诈识别\n",
    "> 2. 用户离网分析\n",
    "> 3. 图像分类\n",
    "\n",
    "4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?  \n",
    "Ans:\n",
    "> 通过解析（parsing）和模式（pattern）匹配的方法，由于人类语言复杂多样，若需要准确率上升，需要不断地叠加语言的模式和规则（patterns and rules），且规则叠加得越多，程序越趋于严格，缺乏适当的容错性，稍微偏离语法将导致程序或结果出错。  \n",
    "> 通过概率（probability）的方式，将语言相关指标转化为较为简单的数学模型，只要数据越多，就越能得到正确的结果，且就实际应用来看，概率模型效果也往往较好。\n",
    "\n",
    "5. What's the Language Model;  \n",
    "Ans:\n",
    "> 语言模型反应一个句子或一段文本出现的概率，是若干词语基于训练语料库按一定顺序组成这个句子的概率似然。\n",
    "\n",
    "6. Can you came up with some sceneraies at which we could use Language Model?  \n",
    "Ans:\n",
    "> 机器翻译、信息检索\n",
    "\n",
    "7. What's the 1-gram language model;  \n",
    "Ans:\n",
    "> 一元语言模型，即假设一个词语出现的概率与其他词语无关，那么一个句子出现的概率则为组成该句子的词语在预料库中出现的概率之积。\n",
    "> $$ Pr(sentence) = Pr(w_1 \\cdot w_2 \\cdots w_n) = \\prod Pr(w_i) = \\prod \\frac {count(w_i)} N $$ \n",
    "\n",
    "8. What's the disadvantages and advantages of 1-gram language model;  \n",
    "Ans:\n",
    "> 优势：计算简单，计算量小  \n",
    "> 劣势：因假设词语之前相互独立，而实际上一个词语出现的概率与前后词语是有关系的，因此准确率较多元模型低。\n",
    "\n",
    "9. What't the 2-gram models;  \n",
    "Ans:\n",
    "> 二元语言模型，假设当前词语出现的概率只与其前一个词语有关，使用公式表述为：  \n",
    "> $$ Pr(sentence) = Pr(w_1 \\cdot w_2 \\cdots w_n) = \\prod \\frac{count(w_i, w_{i+1})}{count(w_i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"\"\"\n",
    "    result = 寒暄 报数 询问 业务相关 结尾 \n",
    "    报数 = 我是 数字 号 ,\n",
    "    数字 = 单个数字 | 数字 单个数字 \n",
    "    单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "    寒暄 = 称谓 打招呼 | 打招呼\n",
    "    称谓 = 人称 ,\n",
    "    人称 = 先生 | 女士 | 小朋友\n",
    "    打招呼 = 你好 | 您好 \n",
    "    询问 = 请问你要 | 您需要\n",
    "    业务相关 = 玩玩 具体业务\n",
    "    玩玩 = 耍一耍 | 玩一玩\n",
    "    具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "    结尾 = 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_gram = \"\"\"\n",
    "    result = 谁们 日子 干什么 语气\n",
    "    谁们 = 谁 和 人们\n",
    "    谁 = 你 | 我 | 他 | 他们 | 我们 | 你们\n",
    "    人们 = 人们 、 人名 | 人名\n",
    "    人名 = 老张 | 老魏 | 老杨 | 老朱\n",
    "    日子 = 动词想 在 节日\n",
    "    动词想 = 计划 | 打算 | 商量\n",
    "    节日 = 国庆节 | 清明节 | 中秋节 | 元旦节\n",
    "    干什么 = 打牌 | 逛街 | 登山  \n",
    "    语气 = ？ | ！ | 吗？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "introduce_gram = \"\"\"\n",
    "    result = 景区介绍 ， 疑问句\n",
    "    景区介绍 = 景区 介绍\n",
    "    景区 = 黄山 | 西湖 | 华山 | 青城山\n",
    "    介绍 = 是什么 | 是什么 ， 有什么\n",
    "    是什么 = 是 一个 形容词 地方\n",
    "    形容词 = 美丽滴 | 迷人的 | 优美的 | 糟糕的 \n",
    "    有什么 = 有什么 ， 有 数量词 形容词 名词 | 有 数量词 形容词 名词\n",
    "    数量词 = 数词 量词\n",
    "    数词 = 很多 | 一 | 二 | 三\n",
    "    量词 = 条 | 头 | 个 \n",
    "    名词 = 猪 | 蛇妖 | 孔雀 | 鲤鱼\n",
    "    疑问句 = 你 确认词 语气助词\n",
    "    确认词 = 确定 | 认真的 | 骗人的 | 搞笑 | 信\n",
    "    语气助词 = 吧？ | 吗？ | ？\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar_parser(gram_str: str, stmt_split: str = '=', or_split: str = '|') -> dict:\n",
    "    grammar = {}\n",
    "    for line in gram_str.split('\\n'):\n",
    "        if not line.strip(): continue\n",
    "        stmt, expr = line.split(stmt_split)\n",
    "        grammar[stmt.strip()] = [i.strip() for i in expr.split(or_split)]\n",
    "    return grammar\n",
    "\n",
    "import random\n",
    "def generator(grammar: dict, target: str) -> str:\n",
    "    target = target.strip()\n",
    "    if target not in grammar:\n",
    "        return target\n",
    "    else:\n",
    "        choice = random.choice(grammar[target])\n",
    "        return ''.join(generator(grammar, c.strip()) for c in choice.split())\n",
    "\n",
    "def generate(gram_str:str, target: str, stmt_split: str = '=', or_split: str = '|') -> str:\n",
    "    grammar = grammar_parser(gram_str, stmt_split, or_split)\n",
    "    return generator(grammar, target)\n",
    "\n",
    "def generate_n(gram_str:str, target: str, n: int = 5, stmt_split: str = '=', or_split: str = '|'):\n",
    "    assert n >= 1\n",
    "    return (generate(gram_str, target, stmt_split, or_split) for i in range(n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你们和老魏计划在元旦节登山？\n",
      "他和老杨、老魏计划在清明节逛街？\n",
      "你们和老魏、老张、老魏、老魏、老魏打算在清明节逛街吗？\n",
      "我和老杨、老张、老张计划在国庆节登山！\n",
      "你们和老张商量在中秋节打牌吗？\n",
      "\n",
      "\n",
      "华山是一个迷人的地方，有三头美丽滴蛇妖，有二条美丽滴鲤鱼，你确定？\n",
      "西湖是一个优美的地方，有很多头优美的蛇妖，你认真的？\n",
      "华山是一个迷人的地方，有一个糟糕的孔雀，你搞笑吧？\n"
     ]
    }
   ],
   "source": [
    "for i in generate_n(holiday_gram, 'result'): print(i)\n",
    "print('\\n')\n",
    "for i in generate_n(introduce_gram, 'result', 3): print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2. 使用新数据源完成语言模型的训练\n",
    "按照我们上文中定义的prob_2函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "- 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "- 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的2-gram语言模型\n",
    "- 进行文本清洗，获得所有的纯文本\n",
    "- 将这些文本进行切词\n",
    "- 送入之前定义的语言模型中，判断文本的合理程度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,link,name,comment,star\n",
      "1,https://movie.douban.com/subject/26363254/,战狼2,吴京意淫到了脑残的地步，看了恶心想吐,1\n",
      "2,https://movie.douban.com/subject/26363254/,战狼2,首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮番上场，视物理逻辑于不顾，不得不说有钱真好，随意胡闹,2\n",
      "3,https://movie.douban.com/subject/26363254/,战狼2,吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋律，为了煽情而煽情，让人觉得他是个大做作、大谎言家。（7.29更新）片子整体不如湄公河行动，1.整体不够流畅，编剧有毒，台词尴尬；2.刻意做作的主旋律煽情显得如此不合时宜而又多余。,2\n",
      "4,https://movie.douban.com/subject/26363254/,战狼2,凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。,4\n",
      "5,https://movie.douban.com/subject/26363254/,战狼2,中二得很,1\n",
      "6,https://movie.douban.com/subject/26363254/,战狼2,“犯我中华者，虽远必诛”，吴京比这句话还要意淫一百倍。,1\n",
      "7,https://movie.douban.com/subject/26363254/,战狼2,脑子是个好东西，希望编剧们都能有。,2\n",
      "8,https://movie.douban.com/subject/26363254/,战狼2,三星半，实打实的7分。第一集在爱国主旋律内部做着各种置换与较劲，但第二集才真正显露吴京的野心，他终于抛弃李忠志了，新增外来班底让硬件实力有机会和国际接轨，开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶，在理念上，它甚至做到《绣春刀2》最想做到的那部分。,4\n",
      "9,https://movie.douban.com/subject/26363254/,战狼2,开篇长镜头惊险大气引人入胜 结合了水平不俗的快剪下实打实的真刀真枪 让人不禁热血沸腾 特别弹簧床架挡炸弹 空手接碎玻璃 弹匣割喉等帅得飞起！就算前半段铺垫节奏散漫主角光环开太大等也不怕 作为一个中国人 两个小时弥漫着中国强大得不可侵犯的氛围 还是让那颗民族自豪心砰砰砰跳个不停。,4\n"
     ]
    }
   ],
   "source": [
    "! head /mnt/disk1/data/learn/others/movie_comments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl/anaconda3/envs/tensorflow/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "import pandas as pd \n",
    "raw_data = pd.read_csv('/mnt/disk1/data/learn/others/movie_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据清洗成纯文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "凭良心说好看到不像战狼1的续集完虐湄公河行动\n"
     ]
    }
   ],
   "source": [
    "deltab = '，,。.《<》>？?-—_！!…（(）)【[】]'\n",
    "transtab = str.maketrans('', '', deltab)\n",
    "test_str = \"凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。\"\n",
    "print(test_str.translate(transtab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "凭良心说好看到不像战狼1的续集完虐湄公河行动\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'\\w+')\n",
    "test_str = \"凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。\"\n",
    "print(''.join(pattern.findall(test_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_sentence(sentence: str) -> str:\n",
    "    pattern = re.compile(r'\\w+')\n",
    "    return ''.join(pattern.findall(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data['comment2'] = raw_data.apply(lambda x: str(x['comment']).translate(transtab), axis = 1)\n",
    "raw_data['comment2'] = raw_data.apply(lambda x: ''.join(pattern.findall(str(x['comment']))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "      <th>comment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "      <td>吴京意淫到了脑残的地步看了恶心想吐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "      <td>首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "      <td>凭良心说好看到不像战狼1的续集完虐湄公河行动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "      <td>中二得很</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \\\n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1   \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2   \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2   \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4   \n",
       "4                                               中二得很    1   \n",
       "\n",
       "                                            comment2  \n",
       "0                                  吴京意淫到了脑残的地步看了恶心想吐  \n",
       "1  首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视...  \n",
       "2  吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了...  \n",
       "3                             凭良心说好看到不像战狼1的续集完虐湄公河行动  \n",
       "4                                               中二得很  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261497, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = list(raw_data['comment2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫到了脑残的地步看了恶心想吐',\n",
       " '首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红的英雄梦各种装备轮番上场视物理逻辑于不顾不得不说有钱真好随意胡闹',\n",
       " '吴京的炒作水平不输冯小刚但小刚至少不会用主旋律来炒作吴京让人看了不舒服为了主旋律而主旋律为了煽情而煽情让人觉得他是个大做作大谎言家729更新片子整体不如湄公河行动1整体不够流畅编剧有毒台词尴尬2刻意做作的主旋律煽情显得如此不合时宜而又多余']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用jieba切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.547 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['凭良心说', '好', '看到', '不像', '战狼', '1', '的', '续集', '完虐', '湄公河', '行动']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba as jeb \n",
    "list(jeb.cut(\"凭良心说好看到不像战狼1的续集完虐湄公河行动\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in clean_text:\n",
    "    if not i.strip(): continue\n",
    "    words.extend(list(jeb.cut(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4490313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 语言模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words_count = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "print(type(words_count))\n",
    "word_with_count = {}\n",
    "for word, count in words_count.most_common(): \n",
    "    word_with_count[word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328262),\n",
       " ('了', 102420),\n",
       " ('是', 73106),\n",
       " ('我', 50338),\n",
       " ('都', 36255),\n",
       " ('很', 34712),\n",
       " ('看', 34022),\n",
       " ('电影', 33675),\n",
       " ('也', 32065),\n",
       " ('和', 31290)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_with_count.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2gram = [words[i] + words[i + 1] for i in range(len(words) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_2gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2_with_count = {}\n",
    "for word, count in Counter(words_2gram).most_common():\n",
    "    word2_with_count[word] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的电影', 8640),\n",
       " ('看的', 7106),\n",
       " ('都是', 6335),\n",
       " ('让人', 5284),\n",
       " ('的故事', 4709),\n",
       " ('看了', 4585),\n",
       " ('也是', 4408),\n",
       " ('的时候', 4398),\n",
       " ('的人', 4356),\n",
       " ('的是', 4348)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2_with_count.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(word, word_list: dict) -> int:\n",
    "    return word_list[word] if word in word_list else list(word_list.items())[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_count('的是我', word2_with_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prob_2gram(sentence, word_counts, word2_counts) -> float:\n",
    "    words = list(jeb.cut(clean_sentence(sentence)))\n",
    "    words2 = [words[i] + words[i + 1] for i in range(len(words) - 1)]\n",
    "    prob = 1.0\n",
    "    for i in range(len(words) - 1):\n",
    "        prob *= get_word_count(words[i] + words[i + 1], word2_counts) / get_word_count(words[i], word_counts)\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们和老魏、老张、老朱商量在清明节逛街吗？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3299528056103016e-15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = generate(holiday_gram, 'result')\n",
    "print(sentence)\n",
    "sentence_prob_2gram(sentence, word_with_count, word2_with_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小朋友,你好我是5号,请问你要玩一玩打猎吗？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.416431795417057e-24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = generate(host, 'result')\n",
    "print(sentence)\n",
    "sentence_prob_2gram(sentence, word_with_count, word2_with_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 获得最优质的的语言\n",
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成n个句子，并能选择一个最合理的句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(gram_str: str, target: str, n: int, word_with_count: dict, word2_with_count: dict, verbose = False):\n",
    "    sentences = generate_n(gram_str, target, n)\n",
    "    sts = []\n",
    "    for sentence in sentences:\n",
    "        prob = sentence_prob_2gram(sentence, word_with_count, word2_with_count)\n",
    "        if verbose: print(\"prob: {0}, \\tsentence: {1}\".format(prob, sentence))\n",
    "        sts.append((sentence, prob))\n",
    "    sts.sort(key=lambda x: x[1], reverse=True)\n",
    "    if verbose: print(\"\\nthe best is: \\nprob: {0}, \\tsentence: {1}\".format(sts[0][1], sts[0][0]))\n",
    "    return sts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob: 4.3859505248924125e-33, \tsentence: 我们和老朱、老杨、老杨、老朱商量在国庆节逛街！\n",
      "prob: 1.2654615798627195e-17, \tsentence: 他和老朱打算在中秋节登山？\n",
      "prob: 7.570993843621385e-20, \tsentence: 你和老杨计划在国庆节登山吗？\n",
      "prob: 1.5809930775826447e-13, \tsentence: 他和老张商量在元旦节登山！\n",
      "prob: 2.0369596274965617e-26, \tsentence: 你们和老张、老朱、老朱、老朱打算在国庆节逛街吗？\n",
      "prob: 5.678022017483305e-17, \tsentence: 你和老朱、老朱、老朱、老魏、老张、老朱打算在清明节登山？\n",
      "prob: 4.209971239359697e-13, \tsentence: 他们和老魏商量在元旦节登山？\n",
      "prob: 8.202065795406515e-19, \tsentence: 他和老朱打算在清明节登山吗？\n",
      "prob: 5.2408610306607005e-15, \tsentence: 他和老魏、老张打算在清明节逛街！\n",
      "prob: 2.380070421916883e-19, \tsentence: 他们和老杨、老魏打算在中秋节逛街吗？\n",
      "prob: 4.456823000077863e-16, \tsentence: 你和老张、老杨打算在元旦节打牌吗？\n",
      "prob: 1.6288038233572481e-15, \tsentence: 我和老张商量在中秋节逛街吗？\n",
      "prob: 6.511289074423595e-19, \tsentence: 他和老魏、老朱商量在国庆节逛街吗？\n",
      "prob: 1.5199460635546306e-15, \tsentence: 我们和老张、老杨商量在中秋节逛街？\n",
      "prob: 7.060748409827585e-16, \tsentence: 他们和老张、老朱计划在元旦节打牌？\n",
      "prob: 1.2419480513692675e-22, \tsentence: 他们和老杨、老朱商量在国庆节逛街！\n",
      "prob: 4.451436213387224e-19, \tsentence: 他和老杨计划在清明节逛街吗？\n",
      "prob: 1.1767914016379307e-15, \tsentence: 他们和老魏计划在元旦节打牌吗？\n",
      "prob: 4.461057628881516e-16, \tsentence: 我们和老魏计划在元旦节登山吗？\n",
      "prob: 4.9953747764348576e-18, \tsentence: 我们和老朱商量在国庆节打牌吗？\n",
      "\n",
      "the best is: \n",
      "prob: 4.209971239359697e-13, \tsentence: 他们和老魏商量在元旦节登山？\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'他们和老魏商量在元旦节登山？'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(holiday_gram, 'result', 20, word_with_count, word2_with_count, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
